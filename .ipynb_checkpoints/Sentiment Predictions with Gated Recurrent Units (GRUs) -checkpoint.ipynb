{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The IMDB movie review dataset\n",
    "Keras provides a **one-dimensional convolutional net** to examine the **IMDB movie review dataset**. Each data point is prelabeled with a `0` (**negative sentiment**) or a `1` (**positive sentiment**). However, we are going to swap out their example IMDB movie review dataset for one in raw text, so we can get our hands dirty with the preprocessing of the text as well. We’ll use the trained model to classify novel review text it has never seen before.\n",
    "\n",
    "This raw dataset contains movie reviews along with their associated binary sentiment polarity labels. It is intended to serve as a benchmark for sentiment classification.\n",
    "The core dataset contains `50,000` reviews split evenly into `25,000` train and `25,000` test sets. The overall distribution of labels is balanced (`25,000` pos and `25,000` neg). In addition to the review text files, the maintainers of the dataset include already-tokenized bag of words (BoW) features that were used in their experiments (we are not going to use the BOW but prepare ours from the raw dataset). *See the dataset maintainers' README file contained in the release for more details*.\n",
    "\n",
    "Link to dataset: https://ai.stanford.edu/%7eamaas/data/sentiment/ **Learning Word Vectors for Sentiment Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess the data\n",
    "### Import Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_data(filepath):\n",
    "    \"\"\"This function shall be used to load and preprocess both train and test datasets\"\"\"\n",
    "    positive_path = os.path.join(filepath, 'pos')\n",
    "    negative_path = os.path.join(filepath, 'neg')\n",
    "    pos_label = 1\n",
    "    neg_label = 0\n",
    "    dataset = []\n",
    "    \n",
    "    for filename in glob.glob(os.path.join(positive_path, '*.txt')):\n",
    "        with open(filename, 'r', encoding = 'utf-8') as f:\n",
    "            dataset.append((pos_label, f.read()))\n",
    "            \n",
    "    for filename in glob.glob(os.path.join(negative_path, '*.txt')):\n",
    "        with open(filename, 'r', encoding = 'utf-8') as f:\n",
    "            dataset.append((neg_label, f.read()))\n",
    "    shuffle(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the *target labels* from the loaded datasets...\n",
    "### Target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_labels(dataset):\n",
    "    \"\"\" Extract the target labels from the dataset \"\"\"\n",
    "    target_labels = []\n",
    "    for sample in dataset:\n",
    "        target_labels.append(sample[0])\n",
    "    return target_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Tokenizer and Vectorizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our *feature engineering*, we are going to employ Google's **Word2vec** model developed by *Thomas Mikolov and team* in 2013 to generate Word2Vec embeddings. The word vector representation from Word2vec **captures much more specific and more precise meaning or semantics of the target word** than the  word-topic vectors generated by **Latent Semantic Analysis (LSA)** and **Latent Dirichlet allocation (LDiA)**.\n",
    "\n",
    "We are limiting our vocab to just `500,000` words due to lack of sufficient memory. This means our *Google Word2vec* word vectors would not contain all the words in our dataset. For such no match cases we shall skip those words during tokenization in order to bypass the errors and continue with the rest of the words.\n",
    "Google's Word2vec binary file source: https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_file = '../word2vec-GoogleNews-vectors/GoogleNews-vectors-negative300.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format(word2vec_file, binary = True, limit = 500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_vectorize(dataset):\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    vectorized_data = []\n",
    "    for sample in dataset:\n",
    "        tokens = tokenizer.tokenize(sample[1])\n",
    "        sample_vecs = []\n",
    "        for token in tokens:\n",
    "            try:\n",
    "                sample_vecs.append(word_vectors[token])\n",
    "            except KeyError:\n",
    "                pass                                   # if no matching token in the Google w2v vocab\n",
    "        vectorized_data.append(sample_vecs)\n",
    "    return vectorized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize the thought vector size\n",
    "The size of our thought vector in very important because it determines the number of time steps and the number of weights in the feed forward layer to train. But most importantly the size of our thought vector determines the *distance* the **backpropagation had to travel** each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_len(data, maxlen):\n",
    "    total_len = truncated = exact = padded = 0\n",
    "    for sample in data:\n",
    "        total_len += len(sample)\n",
    "        if len(sample) > maxlen:\n",
    "            truncated += 1\n",
    "        elif len(sample) < maxlen:\n",
    "            padded += 1\n",
    "        else:\n",
    "            exact += 1\n",
    "    print('Padded: {}'.format(padded))\n",
    "    print('Equal: {}'.format(exact))\n",
    "    print('Truncated: {}'.format(truncated))\n",
    "    print('Avg length: {}'.format(total_len/len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = '../aclImdb/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pre_process_data(train_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " '...am i missing something here??? \"unexpected plot developments\"? \"plot twisting with subversive glee\"? are these viewers watching the same Arquette vehicle to which i just subjected myself (in an now-obvious sub(un)conscious bout of sadomasochism)...I just joined this site simply to make sure that no one else ever rents this stinker...this movie was an embarrassment to every single person involved...quick question: did Sir Stevie read the script before he gave the thumbs-up to Kate C.? if so, then it must be the same Spielberg who greenlighted \"howard the duck\"...don\\'t give me that, \"it was a hit play\" crap--i\\'m guessing Mssr. Reddin ain\\'t too pleased ...the DVD cover promised \"surprising corners\" and a \"twisted story...\" Story!!Story?? It\\'s crap like this that make old Bobby McKee and his wandering band of Structuralists sound like geniuses...Sundance??Berlin??Toronto?? I have a home video of my cat farting that evokes more interest than Arquette\\'s negatively-dimensional portrayal of anguished loss...and, talk about deux ex machina for Mr. Stanley T.; thank god, just in the nick o time he thought to have Dave call the cops! and thank shiva that the cops had just caught the true killer...what!!! up until the credits i was still waiting for it to be some kind of grift against Arquette and his \"hidden millions\"...no, Mrs. Spielberg, you don\\'t escape unscathed: what the hell was that kitchen scene with the \"athlete\\'s foot in my crotch\" gag??? are you worse in this or \"just cause\"?? i dunno...hey film lovers: why don\\'t you make it a blockbuster night and rent this along with \"jersey girl\" and \"white chicks\" and then commit sepukka (or is it seppuka)...and take E. Dunsky with you....')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_train_data = tokenize_and_vectorize(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train_labels = collect_labels(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_path = '../aclImdb/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pre_process_data(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " \"I was really disappointed by this movie. Great actors in it, and potentially a great plot, but it just seemed to limp along.<br /><br />Charlize Theron was masterful in her role and beautiful, but it seemed like 90% of her on-screen work was in car chases done with Austin Minis. Product placement gone wrong, so very wrong.<br /><br />The direction seemed off, too. Edward Norton is the bad guy, and it was so obvious right from the start. Every time the camera would pass over him, it would linger too long and Norton would grimace or something. C'mon, Hollywood, give us a little credit! It's okay to surprise us with a plot twist without having to telegraph it.<br /><br />Sorry, but this movie was just below average. I have always been one to appreciate the work and talent that goes into a movie, but this one just didn't have it.\")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have `25,000` training samples and `25,000` test samples as expected. The next step is to *tokenize* and *vectorize* the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_test_data = tokenize_and_vectorize(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_test_labels = collect_labels(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall pad/truncate our train and test data, convert it to *numpy arrays* as required by Keras for its optimized vectorized operations. This is a *tensor* with the shape (**number of samples**, **sequence length**, **word vector length**) that we need for our GRU model. **We won’t usually need to pad or truncate with RNNs (LSTMs, GRUs), because they can handle input sequences of variable length**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded: 22506\n",
      "Equal: 12\n",
      "Truncated: 2482\n",
      "Avg length: 203.8464\n"
     ]
    }
   ],
   "source": [
    "test_len(vectorized_train_data, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 200\n",
    "batch_size = 32\n",
    "embedding_dims = 300\n",
    "num_neurons = 50\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to pad tokens\n",
    "Keras has a preprocessing helper method, **pad_sequences**, that in theory could be used to pad our input data, but unfortunately *it works only with sequences of scalars*, but we have *sequences of vectors*. Let’s write a helper function to pad our input sequence of vectors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_trunc(data, maxlen):\n",
    "    \"\"\"\n",
    "    For a given dataset pad with zero vectors or truncate to maxlen\n",
    "    \"\"\"\n",
    "    # This one-liner can accomplish the same task!\n",
    "    # return [sample[:maxlen] + [[0.] * embedding_dims] * (maxlen - len(sample)) for sample in data]\n",
    "    \n",
    "    new_data = []\n",
    "    # Create a vector of 0s the length of our word vectors\n",
    "    zero_vector = []\n",
    "    for _ in range(len(data[0][0])):\n",
    "        zero_vector.append(0.0)\n",
    "    for sample in data:\n",
    "        if len(sample) > maxlen:\n",
    "            temp = sample[:maxlen]\n",
    "        elif len(sample) < maxlen:\n",
    "            temp = sample\n",
    "            # Append the appropriate number 0 vectors to the list\n",
    "            additional_elems = maxlen - len(sample)\n",
    "            for _ in range(additional_elems):\n",
    "                temp.append(zero_vector)\n",
    "        else:\n",
    "            temp = sample\n",
    "        new_data.append(temp)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_trunc(vectorized_train_data, maxlen)\n",
    "X_test = pad_trunc(vectorized_test_data, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (len(X_train), maxlen, embedding_dims))\n",
    "y_train = np.array(target_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.reshape(X_test, (len(X_test), maxlen, embedding_dims))\n",
    "y_test = np.array(target_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07910156, -0.0050354 ,  0.11181641, ..., -0.0067749 ,\n",
       "         0.04272461, -0.10351562],\n",
       "       [ 0.09667969, -0.07080078, -0.06933594, ...,  0.0189209 ,\n",
       "         0.13574219,  0.19140625],\n",
       "       [-0.06640625,  0.19921875, -0.22460938, ...,  0.13476562,\n",
       "         0.22070312, -0.26757812],\n",
       "       ...,\n",
       "       [ 0.22851562,  0.04516602,  0.09521484, ..., -0.08056641,\n",
       "        -0.08398438,  0.01611328],\n",
       "       [-0.03442383,  0.10351562,  0.02160645, ...,  0.07324219,\n",
       "         0.03320312,  0.03833008],\n",
       "       [-0.02490234,  0.02197266, -0.03540039, ...,  0.01080322,\n",
       "        -0.01879883, -0.06884766]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 300)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 200, 300)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07910156, -0.0050354 ,  0.11181641, ..., -0.0067749 ,\n",
       "         0.04272461, -0.10351562],\n",
       "       [ 0.19335938, -0.07128906,  0.10839844, ...,  0.0480957 ,\n",
       "         0.16503906,  0.04418945],\n",
       "       [ 0.12597656,  0.19042969,  0.06982422, ...,  0.0612793 ,\n",
       "         0.17285156, -0.07861328],\n",
       "       ...,\n",
       "       [-0.03369141,  0.05151367,  0.02368164, ...,  0.27148438,\n",
       "         0.01324463, -0.19140625],\n",
       "       [-0.02368164,  0.10791016, -0.13574219, ..., -0.21386719,\n",
       "        -0.08251953, -0.0168457 ],\n",
       "       [-0.6015625 , -0.08398438,  0.05395508, ...,  0.10107422,\n",
       "         0.05688477, -0.20898438]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 300)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 200, 300)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the LSTM model\n",
    "### Import required packages and modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize model and add a GRU layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.GRU(\n",
    "    num_neurons, \n",
    "    return_sequences = True,\n",
    "    input_shape = (maxlen, embedding_dims)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our sequences are `200` (maxlen) tokens long and we’re using `50` hidden **neurons**, our output from this layer will be a vector of `200` elements long. Each of those elements is a vector `50` elements long, with **one output for each of the neurons** (Each token is processed by `50` neurons to out a vector of length `50` bundled into an output vector of length `200`). The output is therefore a list of lists where the inner list are `200` and each is of length `50`!\n",
    "The keyword argument `return_sequences` will tell the network to return the network value at each *time step*, hence the `200` vectors, each `50` elements long. If `return_sequences` is set to *False*, the model will be a feedforward and *not* an RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a dropout and output layers\n",
    "To prevent *overfitting* we add a **Dropout layer** to zero out `20%` of those inputs, randomly chosen on each input example. And then finally we add a classifier. In this case, we have **binary classification** task: *Yes or Positive Sentiment* is labeled `1` and *No or Negative Sentiment* is labeled `0`. So we chose a layer with one neuron (Dense(1)) and a `sigmoid` activation function. But a Dense layer expects a “*flat*” vector of **n elements** (each element a float) as input. And the data coming out of the *GRU* is a *tensor* `200` elements long, and each of those are `50` elements long. So we use a `Flatten()` layer to flatten the input from a `200 x 50` tensor to a vector `10,000` elements long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru (GRU)                    (None, 200, 50)           52650     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200, 50)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 10001     \n",
      "=================================================================\n",
      "Total params: 62,651\n",
      "Trainable params: 62,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile('rmsprop', 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "20000/20000 [==============================] - 194s 10ms/sample - loss: 0.4831 - acc: 0.7674 - val_loss: 0.4158 - val_acc: 0.8158\n",
      "Epoch 2/2\n",
      "20000/20000 [==============================] - 118s 6ms/sample - loss: 0.3609 - acc: 0.8450 - val_loss: 0.4095 - val_acc: 0.8290\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = epochs,\n",
    "                    validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 91s 4ms/sample - loss: 0.3213 - acc: 0.8682\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_accuracy = model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 86.82%\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy: {}%'.format(round(float(train_accuracy) * 100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 82.24%\n"
     ]
    }
   ],
   "source": [
    "print('Validation Accuracy: {}%'.format(round(sum(val_acc) / len(val_acc) * 100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 131s 5ms/sample - loss: 0.3849 - acc: 0.8380\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 83.8%\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy: {}%'.format(round(float(test_accuracy) * 100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have comparable validation and test accuracies of about `82%` and `83%` respectively. This an indication that *overfitting* of the training data is not a huge problem. However, with a training accuracy of more than `86%` and a test accuracy of about `83%` the model can still be tweaked. We would probably get `2%` - `3%` increase in test score with *LSTM layer*.\n",
    "### Save the model\n",
    "Saving both the model architecture and its weights will allow it to be reloaded and trained from that point on if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_structure = model.to_json()\n",
    "with open(\"./model/gru_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_structure)\n",
    "\n",
    "model.save_weights(\"./model/gru_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload model for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./model/gru_model.json\", \"r\") as json_file:\n",
    "    json_string = json_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "loaded_model = keras.models.model_from_json(json_string)\n",
    "loaded_model.load_weights('./model/gru_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Test example\n",
    "Get some sample reviews from the internet and use the model to predict the reviewers' sentiments regarding the movie...(make sure to remove any sensitive issues like names and replace them with make up ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_text = [\"Loved the film. I wasn’t sure at the start but it was lovely \"+ \\\n",
    "               \"to see all the characters from the small screen arrive in the \"+ \\\n",
    "               \"cinema as old friends, and I laughed and cried. This is a great \"+ \\\n",
    "               \"film and I really hope they make a sequel. \"+ \\\n",
    "               \"To the person who gave this film one star you should have reviewed \"+ \\\n",
    "               \"the film, not the taxi driver and as you didn’t see the first 30 minutes \"+ \\\n",
    "               \"you aren’t in a position to comment on the entire film anyway.\", \n",
    "               \n",
    "               \"I have no doubt that Uptown fans will support this film. We have every \"+ \\\n",
    "               \"episode on DVD, so it is with something of a heavy heart to give this film \"+ \\\n",
    "               \"such a low rating. As a stand-alone film (or if you have never seen the TV series), \"+ \\\n",
    "               \"all you get are lavish scenery and costumes. However, the characters appear shallow \"+ \\\n",
    "               \"and the plot flimsy. As a Uptown fan, yes – the pleasant and familiar characters are \"+ \\\n",
    "               \"there for you to enjoy in their familiar costumes. However, that is not enough. \"+ \\\n",
    "               \"Soon into the film, we found that the depth of our characters was not there. \"+ \\\n",
    "               \"I can only allude to metaphors. It was like watching a Formula One race run at \"+ \\\n",
    "               \"20 mph – where was the excitement? It was like watching a Weakenhand ruby game of \"+ \\\n",
    "               \"touch rugby – all spectacle but no impact. It was like being forced to lie in a bubble \"+ \\\n",
    "               \"bath of lukewarm water for too long. Even a couple of people around gave up and stated \"+ \\\n",
    "              \"playing with their iPhone, with mutterings as we left at it was far too long. \"+ \\\n",
    "               \"Maybe it was our local cinema’s projection but even the film quality was nothing \"+ \\\n",
    "               \"like my Blu-ray at home, let along 4K. So, all in all, this is best seen as a light touch \"+ \\\n",
    "               \"homage to the TV series. Bearing in mind the trouble taken to assemble the actors in one \"+ \\\n",
    "               \"place at one time to make this movie, this was a wasted opportunity to create a real Uptown epic. \"+ \\\n",
    "               \"I hope they do not make a sequel.\"\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1 = review_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_sample_1 = tokenize_and_vectorize([(1, sample_1)])                                            # tokenize and vectorize\n",
    "test_vec_sample_1 = pad_trunc(vec_sample_1, maxlen)                                               # padding / truncate\n",
    "test_vec1 = np.reshape(test_vec_sample_1, (len(test_vec_sample_1), maxlen, embedding_dims))       # reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment class: [[1]]\n"
     ]
    }
   ],
   "source": [
    "print('Sentiment class: {}'.format(loaded_model.predict_classes(test_vec1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_2 = review_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_sample_2 = tokenize_and_vectorize([(1, sample_2)])                                           \n",
    "test_vec_sample_2 = pad_trunc(vec_sample_2, maxlen)                                               \n",
    "test_vec2 = np.reshape(test_vec_sample_2, (len(test_vec_sample_2), maxlen, embedding_dims))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment class: [[1]]\n"
     ]
    }
   ],
   "source": [
    "print('Sentiment class: {}'.format(loaded_model.predict_classes(test_vec2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_3 = 'The story has no center; the duck is not likable, and the costly, overwrought, laser-filled special effects '+ \\\n",
    "'that conclude the movie are less impressive than a sparkler on a birthday cake. James ‘Star Wars’ Luke supervised the ' + \\\n",
    "'production of this film, and maybe it’s time he went back to making low-budget films like his best picture'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_sample_3 = tokenize_and_vectorize([(1, sample_3)])                                           \n",
    "test_vec_sample_3 = pad_trunc(vec_sample_3, maxlen)                                               \n",
    "test_vec3 = np.reshape(test_vec_sample_3, (len(test_vec_sample_3), maxlen, embedding_dims))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment class: [[0]]\n"
     ]
    }
   ],
   "source": [
    "print('Sentiment class: {}'.format(loaded_model.predict_classes(test_vec3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model seems to be doing a good job!\n",
    "\n",
    "The `predict_classes()` method gives the expected `0` or `1` for a binary classification task. The `.predict()` method reveals the raw `sigmoid` activation function output (a continuous value between `0` and `1`) before thresholding. Anything **above** `0.5` will be classified as positive (`1`) and **below** `0.5` will be negative (`0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output of sigmoid function for sample_1: [[0.8725347]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw output of sigmoid function for sample_1: {}\".format(loaded_model.predict(test_vec1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output of sigmoid function for sample_2: [[0.6017147]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw output of sigmoid function for sample_2: {}\".format(loaded_model.predict(test_vec2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output of sigmoid function for sample_3: [[0.43969184]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw output of sigmoid function for sample_3: {}\".format(loaded_model.predict(test_vec3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
